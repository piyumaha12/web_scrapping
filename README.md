# Web Scrapping

![sai-kiran-anagani-5Ntkpxqt54Y-unsplash](https://user-images.githubusercontent.com/71897685/150558930-f719a45b-4e3f-462f-9361-a0dbedec03aa.jpg)


This repository contains all codes related to webscrapping.

Here I have used BeautifulSoup, requests, urllib, pandas, numpy libraries

- [web_scrapping_text_file_writing.py](https://github.com/piyumaha12/web_scrapping/blob/b029dc0ee856d3c45c28da4200945c3b5b4ae817/web_scrapping_text_file_writing.py) This file is used for scrapping reviews from Amazon website in my project [Sentiment_analysis_on_amazon_review](https://github.com/piyumaha12/Sentiment_analysis_on_amazon_review.git). This file stores the reviews in steps, So even If you face any error when file is running and some review got extracted, then you don't need to start from start, else you can start from your last point

- [extraction_ai.ipynb](https://github.com/piyumaha12/web_scrapping/blob/58d8fe7453c330175844dec62ab506990ff67b11/extraction_ai.ipynb), This extraction file extracts info from urls given in Excel file [Input.xlsx](https://github.com/piyumaha12/web_scrapping/blob/58d8fe7453c330175844dec62ab506990ff67b11/Input.xlsx).
